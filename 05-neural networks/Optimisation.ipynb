{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation of a scalar function\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive example\n",
    "---\n",
    "\n",
    "We ware interested in a method that can find a local minimum of a continuous function, only being able to evaluate the gradient. In that case, we can just follow the gradient for small step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x ** 2\n",
    "df = lambda x: 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set a few values to do the optimisation. For one, we need a starting point: ``wrt``. Then we need to determine how big each step is, that is the step rate. It will be used to multiply the gradient with for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_rate = .2\n",
    "wrt = -10\n",
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(wrt, f, df, step_rate, n_steps):\n",
    "    path = [wrt]\n",
    "    for i in range(n_steps):\n",
    "        wrt -= step_rate * df(wrt)\n",
    "        path.append(wrt)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us produce several runs and save the solution path during the optimisation.\n",
    "We will then inspect the different routes afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_path_x2_0 = gradient_descent(wrt, f, df, .1, n_steps)\n",
    "gd_path_x2_1 = gradient_descent(wrt, f, df, .01, n_steps)\n",
    "gd_path_x2_2 = gradient_descent(wrt, f, df, 1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_info1d(minx, maxx, f, paths, ax1, ax2, path_labels=None):\n",
    "    xs = np.linspace(minx, maxx, 100)\n",
    "    ys = f(xs)\n",
    "\n",
    "    ax1.plot(xs, ys, label='$x^2$')\n",
    "    \n",
    "    if path_labels is None:\n",
    "        path_labels = [str(i) for i in range(len(paths))]\n",
    "    \n",
    "    colors = list('krgbmc')\n",
    "    for i, p, l in zip(itertools.count(), paths, path_labels):\n",
    "        path_costs = [f(j) for j in p]\n",
    "        ax1.plot(p, path_costs, '%so-' % colors[i], label=l)\n",
    "        \n",
    "        ax2.plot(path_costs, '%so-' % colors[i], label=l)\n",
    "        ax2.set_xlabel('#iteration')\n",
    "        ax2.set_ylabel('cost')\n",
    "\n",
    "    ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), squeeze=False)\n",
    "\n",
    "opt_info1d(-2, 10, f, [gd_path_x2_0, gd_path_x2_1, gd_path_x2_2], axs[0][0], axs[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a better learning rate\n",
    "---\n",
    "\n",
    "In practice, setting the step rate is difficult and requires manual tuning. For quadratic functions, there is an optimal step rate that is the inverse of the curvature. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = lambda x: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvature_descent(wrt, f, df, ddf, n_steps):\n",
    "    path = [wrt]\n",
    "    for i in range(n_steps):\n",
    "        step_rate = abs(1. / ddf(wrt))\n",
    "        wrt -= step_rate * df(wrt)\n",
    "        path.append(wrt)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_path_x2 = curvature_descent(wrt, f, df, ddf, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), squeeze=False)\n",
    "\n",
    "opt_info1d(-2, 10, f, [gd_path_x2_1, cd_path_x2], axs[0][0], axs[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more difficult problem\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x ** 4\n",
    "df = lambda x: 4 * x ** 3\n",
    "ddf = lambda x: 12 * x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrt = 1\n",
    "gd_path_sin_0 = gradient_descent(wrt, f, df, .1, n_steps)\n",
    "cd_path_sin = curvature_descent(wrt, f, df, ddf, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), squeeze=False)\n",
    "\n",
    "opt_info1d(-.5, 1.5, f, [gd_path_sin_0, cd_path_sin], axs[0][0], axs[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more difficult problem\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.sin(x)\n",
    "df = lambda x: np.cos(x)\n",
    "ddf = lambda x: -np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrt = 1\n",
    "gd_path_sin_0 = gradient_descent(wrt, f, df, .1, n_steps)\n",
    "cd_path_sin = curvature_descent(wrt, f, df, ddf, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), squeeze=False)\n",
    "\n",
    "opt_info1d(-5, 10, f, [gd_path_sin_0, cd_path_sin], axs[0][0], axs[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
