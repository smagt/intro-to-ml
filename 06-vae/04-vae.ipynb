{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The variational autoencoder\n",
    "\n",
    "A \"new\" model presented in 2013/2014, this is since then one of the most important models used for unsupervised learning.\n",
    "\n",
    "The VAE is a probabilistic AE with strong advantages,as published in https://arxiv.org/abs/1312.6114 and https://proceedings.mlr.press/v32/rezende14.html\n",
    "\n",
    "This notebook (c) Patrick van der Smagt, March 2023, heavily building on various internet sources.  Please do not distribute this without Patrick's consent, since he nicked from the internet.\n",
    "\n",
    "Sources used: https://github.com/ANLGBOY/VAE-with-PyTorch/, https://avandekleut.github.io/vae/, https://github.com/pytorch/examples/blob/main/vae/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    # the following may be necessary on Mac with M1/M2 arch and some versions of PyTorch, \n",
    "    # which allows it to fall back to CPU computing if the graphics card (MPS) implementation fails.\n",
    "    os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a lightning module, with lots of magic numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, latent_dim, dataset):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.data_dir = \"./data\"\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.batch_size = 128\n",
    "        self.h1size = 512\n",
    "        self.h2size = 256\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        self.nnsize = channels * width * height\n",
    "\n",
    "        self.fc1 = nn.Linear(self.nnsize, self.h1size)\n",
    "        self.fc2 = nn.Linear(self.h1size, self.h2size)\n",
    "        self.fc21 = nn.Linear(self.h2size, latent_dim)  # fc21 for mean of Z\n",
    "        self.fc22 = nn.Linear(self.h2size, latent_dim)  # fc22 for log variance of Z\n",
    "        self.fc3 = nn.Linear(latent_dim, self.h2size)\n",
    "        self.fc4 = nn.Linear(self.h2size, self.h1size)\n",
    "        self.fc5 = nn.Linear(self.h1size, self.nnsize)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        mu = self.fc21(h2)\n",
    "        # use logvar instead of var since the output of fc22 can be negative (var is always positive)\n",
    "        logvar = self.fc22(h2)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.relu(self.fc4(h3))\n",
    "        out = self.fc5(h4)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch size, 1, 28,28] -> x: [batch size, 784]\n",
    "        x = x.view(-1, self.nnsize)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        # Reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(recon_x, x.view(-1, self.nnsize), reduction='sum')\n",
    "        # KL divergence loss\n",
    "        kld_loss = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "        loss = (recon_loss + kld_loss) # / x.size(0)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        recon_x, mu, logvar = self(x)\n",
    "        loss = self.loss_function(recon_x, x, mu, logvar)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        recon_x, mu, logvar = self(x)\n",
    "        loss = self.loss_function(recon_x, x, mu, logvar)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)  # this learning rate is the default one for adam in Pytorch\n",
    "        return optimizer\n",
    "\n",
    "    def setup(self, stage=None):        \n",
    "        dataset_full = eval(self.dataset)(self.data_dir, train=True, download=True, transform=transforms.ToTensor())\n",
    "        self.dataset_train, self.dataset_val = random_split(dataset_full, [55000, 5000])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=self.batch_size, num_workers=8)\n",
    "    \n",
    "# now we create the vae, with a specific latent space\n",
    "vae_fashion = VAE(2, 'FashionMNIST')\n",
    "vae_mnist = VAE(2, 'MNIST')\n",
    "\n",
    "# choose one we play with\n",
    "model = vae_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tensorlogs\", name=\"vae\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot of reconstruction\n",
    "Put an image in the encoder; then have it reconstructed at the decoder.  Show the images side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval; # put in evaluation mode\n",
    "offset = 0  # you can plot other digits by increasing this\n",
    "fig = plt.figure()\n",
    "for i in range(4):\n",
    "  plt.subplot(2,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(model.dataset_train.dataset[i+offset][0][0], cmap='gray', interpolation='none')\n",
    "  plt.subplot(2,4,i+5)\n",
    "  pred = model(model.dataset_train.dataset[i+offset][0])[0].detach().numpy().reshape(28,28)\n",
    "  plt.imshow(pred, cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "model.train; # back in training mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train more\n",
    "Go back to training more epochs.  Then you can go back to the above and check if the reconstruction improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit_loop.max_epochs = 20\n",
    "trainer.fit(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now do some plotting\n",
    "We show the distribution of classes in the 2-dimensional latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(autoencoder, data, num_batches=100):\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        z, var = autoencoder.encode(x.view(-1, model.nnsize))\n",
    "        z = z.to('cpu').detach().numpy()\n",
    "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n",
    "        if i > num_batches:\n",
    "            plt.colorbar()\n",
    "            break\n",
    "plot_latent(model, model.train_dataloader() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed(autoencoder, r0=(-1.5, 1.5), r1=(-1.5, 1.5), n=12):\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]) #.to(device)\n",
    "            x_hat = autoencoder.decode(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    plt.imshow(img, extent=[*r0, *r1])\n",
    "plot_reconstructed(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
